{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# # Required libraries\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from flask import Flask, request\n",
    "import html\n",
    "\n",
    "import pickle\n",
    "\n",
    "from nltk.stem import SnowballStemmer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "my_home = \"/home/muths/p6\"\n",
    "my_home = \"..\"\n",
    "my_data = my_home + '/data'\n",
    "my_html = my_home + '/html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load objects from Pickle\n",
    "stem_file = open(my_home + '/pkl/stem_vectorizer.pkl', 'rb')\n",
    "stem_vectorizer = pickle.load(stem_file)\n",
    "stem_file.close()\n",
    "\n",
    "classifier_file = open(my_home + '/pkl/MultiLabelClassif.pkl', 'rb')\n",
    "MultiLabelClassif = pickle.load(classifier_file)\n",
    "classifier_file.close()\n",
    "\n",
    "tags_file = open(my_home + '/pkl/tag_df.pkl', 'rb')\n",
    "tag_df = pickle.load(tags_file)\n",
    "tags_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to return the recommended tags\n",
    "def predict_tags(title=None, body=None):\n",
    "    # Take only aplanumeric words, no punctuation signs\n",
    "    tokenizer = nltk.RegexpTokenizer('\\w+')\n",
    "\n",
    "    # Prepare set of stopwords\n",
    "    stopWords = set(stopwords.words('english'))\n",
    "\n",
    "    # Define stemmer\n",
    "    snowball_stemmer = SnowballStemmer(\"english\")\n",
    "    \n",
    "    newWordsArray = []\n",
    "\n",
    "    html_text = title + \" \" + body\n",
    "    soup = BeautifulSoup(html_text, \"lxml\").get_text()\n",
    "    words = tokenizer.tokenize(soup.lower())\n",
    "    his_words = ''\n",
    "    for w in words:\n",
    "        if (w not in stopWords):\n",
    "            stem = snowball_stemmer.stem(w)\n",
    "            his_words = his_words + ' ' + stem\n",
    "    newWordsArray.append(his_words)\n",
    "\n",
    "    # Vectorize stems using trained vectorizer\n",
    "    stem_vector_new = stem_vectorizer.transform(newWordsArray)\n",
    "    \n",
    "    # Predic proba for each tag to be relevant for the question\n",
    "    new_predict_proba = MultiLabelClassif.predict_proba(stem_vector_new)\n",
    "    \n",
    "    proposed_tags = ''\n",
    "    for i in new_predict_proba[0].argsort()[:-10-1:-1]:\n",
    "        proposed_tag = tag_df.iloc[i]['names']\n",
    "        if new_predict_proba[0][i] > 0.05:\n",
    "            proposed_tag = \"<b>\" + proposed_tag + \"</b>\"\n",
    "        proposed_tags += (proposed_tag) + \"<br/>\"\n",
    "        \n",
    "    return proposed_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [01/Jun/2018 14:35:55] \"GET /p6/input HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/Jun/2018 14:36:12] \"POST /p6/tag_reco HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/Jun/2018 14:37:26] \"GET /p6/input HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/Jun/2018 14:37:43] \"POST /p6/tag_reco HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/p6/input')\n",
    "def quesion():\n",
    "\n",
    "    #Build input form for questions\n",
    "    body=\"\"\n",
    "   \n",
    "    #Read HTML header and footer files\n",
    "    with open(my_html + '/header.html', 'r') as header:\n",
    "        html_header=header.read()\n",
    "    with open(my_html + '/footer.html', 'r') as footer:\n",
    "        html_footer=footer.read()\n",
    "    return html_header + body + html_footer\n",
    "\n",
    "@app.route('/p6/tag_reco', methods=['GET', 'POST'])\n",
    "def tag_reco():\n",
    "    title = request.form['title']\n",
    "    body = request.form['body']\n",
    "    proposed_tags = predict_tags(title, body)\n",
    "    \n",
    "    reminder = \"<h2>Your question</h2>\"\n",
    "    reminder += \"<h3>\" + title + \"</h3>\"\n",
    "    reminder += body\n",
    "    \n",
    "    #Read HTML header and footer files\n",
    "    with open(my_html + '/header_resp.html', 'r') as header:\n",
    "        html_header=header.read()\n",
    "    with open(my_html + '/footer_resp.html', 'r') as footer:\n",
    "        html_footer=footer.read()\n",
    "    return html_header + proposed_tags + reminder + html_footer\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
